{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "807d47d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MULTI-CLASS MENTAL HEALTH DATA PREPARATION\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MULTI-CLASS MENTAL HEALTH DATA PREPARATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "DATA_PATH = 'mental_health_data.csv'\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(f\"\\n? Error: {DATA_PATH} not found!\")\n",
    "    exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b79b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/8] Loading dataset from mental_health_data.csv...\n",
      "+ Loaded 53043 samples\n",
      "Columns: ['Unnamed: 0', 'statement', 'status']\n"
     ]
    }
   ],
   "source": [
    "# ============= LOAD DATA =============\n",
    "print(f\"\\n[1/8] Loading dataset from {DATA_PATH}...\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"+ Loaded {len(df)} samples\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "except Exception as e:\n",
    "    print(f\"? Error loading data: {e}\")\n",
    "    exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c4bbcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/8] Exploring dataset...\n",
      "\n",
      "+ Dataset Info:\n",
      "Total samples: 53043\n",
      "\n",
      "First few rows:\n",
      "   Unnamed: 0                                          statement   status\n",
      "0           0                                         oh my gosh  Anxiety\n",
      "1           1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
      "2           2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
      "3           3  I've shifted my focus to something else but I'...  Anxiety\n",
      "4           4  I'm restless and restless, it's been a month n...  Anxiety\n",
      "\n",
      "+ Mental Health Status Distribution:\n",
      "status\n",
      "Normal                  16351\n",
      "Depression              15404\n",
      "Suicidal                10653\n",
      "Anxiety                  3888\n",
      "Bipolar                  2877\n",
      "Stress                   2669\n",
      "Personality disorder     1201\n",
      "Name: count, dtype: int64\n",
      "\n",
      "+ Class percentages:\n",
      "  Normal                     16351 (30.83%)\n",
      "  Depression                 15404 (29.04%)\n",
      "  Suicidal                   10653 (20.08%)\n",
      "  Anxiety                     3888 ( 7.33%)\n",
      "  Bipolar                     2877 ( 5.42%)\n",
      "  Stress                      2669 ( 5.03%)\n",
      "  Personality disorder        1201 ( 2.26%)\n"
     ]
    }
   ],
   "source": [
    "# ============= INITIAL EXPLORATION =============\n",
    "print(\"\\n[2/8] Exploring dataset...\")\n",
    "\n",
    "print(f\"\\n+ Dataset Info:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\n+ Mental Health Status Distribution:\")\n",
    "status_counts = df['status'].value_counts()\n",
    "print(status_counts)\n",
    "print(f\"\\n+ Class percentages:\")\n",
    "for status, count in status_counts.items():\n",
    "    print(f\"  {status:<25} {count:>6} ({count/len(df)*100:>5.2f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4288d0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/8] Setting up 7-class classification...\n",
      "\n",
      "+ Class mapping complete:\n",
      "  [0] Normal                     16351 samples\n",
      "  [1] Anxiety                     3888 samples\n",
      "  [2] Depression                 15404 samples\n",
      "  [3] Stress                      2669 samples\n",
      "  [4] Suicidal                   10653 samples\n",
      "  [5] Bipolar                     2877 samples\n",
      "  [6] Personality disorder        1201 samples\n",
      "\n",
      "+ Saved: models/mental_health_roberta/label_mapping.json\n"
     ]
    }
   ],
   "source": [
    "# ============= DEFINE CLASS MAPPING =============\n",
    "print(\"\\n[3/8] Setting up 7-class classification...\")\n",
    "\n",
    "# Map to standardized class names\n",
    "CLASS_MAPPING = {\n",
    "    'Normal': 0,\n",
    "    'Anxiety': 1,\n",
    "    'Depression': 2,\n",
    "    'Stress': 3,\n",
    "    'Suicidal': 4,\n",
    "    'Bipolar': 5,\n",
    "    'Personality disorder': 6\n",
    "}\n",
    "\n",
    "# Create label column\n",
    "df['label'] = df['status'].map(CLASS_MAPPING)\n",
    "\n",
    "# Remove any unmapped classes\n",
    "unmapped = df[df['label'].isna()]\n",
    "if len(unmapped) > 0:\n",
    "    print(f\"?  Found {len(unmapped)} samples with unmapped classes:\")\n",
    "    print(unmapped['status'].value_counts())\n",
    "    df = df.dropna(subset=['label'])\n",
    "\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "print(f\"\\n+ Class mapping complete:\")\n",
    "for name, idx in sorted(CLASS_MAPPING.items(), key=lambda x: x[1]):\n",
    "    count = (df['label'] == idx).sum()\n",
    "    print(f\"  [{idx}] {name:<25} {count:>6} samples\")\n",
    "\n",
    "# Save class mapping\n",
    "os.makedirs('models/mental_health_roberta', exist_ok=True)\n",
    "with open('models/mental_health_roberta/label_mapping.json', 'w') as f:\n",
    "    json.dump(CLASS_MAPPING, f, indent=2)\n",
    "print(\"\\n+ Saved: models/mental_health_roberta/label_mapping.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4e6cc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/8] Cleaning data...\n",
      "After removing nulls: 50083 (100.0%)\n",
      "After removing duplicates: 50083 (100.0%)\n",
      "After length filtering (10-5000 chars): 50083 (100.0%)\n",
      "After word count filtering (>=3 words): 50083 (100.0%)\n",
      "\n",
      "+ Cleaned dataset: 50083 samples (100.0% retained)\n"
     ]
    }
   ],
   "source": [
    "# ============= DATA CLEANING =============\n",
    "print(\"\\n[4/8] Cleaning data...\")\n",
    "\n",
    "original_size = len(df)\n",
    "\n",
    "# Remove nulls\n",
    "df = df.dropna(subset=['statement', 'label'])\n",
    "print(f\"After removing nulls: {len(df)} ({len(df)/original_size*100:.1f}%)\")\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates(subset=['statement'])\n",
    "print(f\"After removing duplicates: {len(df)} ({len(df)/original_size*100:.1f}%)\")\n",
    "\n",
    "# Add text statistics\n",
    "df['text_length'] = df['statement'].str.len()\n",
    "df['word_count'] = df['statement'].str.split().str.len()\n",
    "df['avg_word_length'] = df['statement'].apply(\n",
    "    lambda x: np.mean([len(word) for word in str(x).split()]) if len(str(x).split()) > 0 else 0\n",
    ")\n",
    "\n",
    "# Filter by text length\n",
    "df = df[(df['text_length'] >= 10) & (df['text_length'] <= 5000)]\n",
    "print(f\"After length filtering (10-5000 chars): {len(df)} ({len(df)/original_size*100:.1f}%)\")\n",
    "\n",
    "# Filter by word count\n",
    "df = df[df['word_count'] >= 3]\n",
    "print(f\"After word count filtering (>=3 words): {len(df)} ({len(df)/original_size*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n+ Cleaned dataset: {len(df)} samples ({len(df)/original_size*100:.1f}% retained)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb6d75e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/8] Analyzing text statistics per class...\n",
      "\n",
      "+ Text Statistics by Mental Health Category:\n",
      "                     text_length              word_count              \\\n",
      "                            mean         std        mean         std   \n",
      "status                                                                 \n",
      "Anxiety               744.754801  742.284513  140.118842  139.865082   \n",
      "Bipolar               930.185393  774.520113  173.260032  144.943391   \n",
      "Depression            796.182068  755.923456  158.749816  149.712414   \n",
      "Normal                 95.038673  122.305803   18.187418   23.053253   \n",
      "Personality disorder  895.494938  751.040234  167.446569  141.282430   \n",
      "Stress                584.583224  486.220051  109.937090   90.419784   \n",
      "Suicidal              693.490868  731.846244  138.819343  144.698839   \n",
      "\n",
      "                     avg_word_length            \n",
      "                                mean       std  \n",
      "status                                          \n",
      "Anxiety                     4.392177  0.609056  \n",
      "Bipolar                     4.406849  0.460657  \n",
      "Depression                  4.066966  0.561082  \n",
      "Normal                      4.345630  1.389797  \n",
      "Personality disorder        4.538480  1.056262  \n",
      "Stress                      4.548696  1.978068  \n",
      "Suicidal                    4.021395  0.538849  \n"
     ]
    }
   ],
   "source": [
    "# ============= TEXT STATISTICS PER CLASS =============\n",
    "print(\"\\n[5/8] Analyzing text statistics per class...\")\n",
    "\n",
    "print(f\"\\n+ Text Statistics by Mental Health Category:\")\n",
    "stats_by_class = df.groupby('status')[['text_length', 'word_count', 'avg_word_length']].agg(['mean', 'std'])\n",
    "print(stats_by_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a790ff1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/8] Analyzing class balance...\n",
      "\n",
      "+ Class Balance Analysis:\n",
      "Largest class:  0 with 15308 samples\n",
      "Smallest class: 6 with 889 samples\n",
      "Imbalance ratio: 17.22:1\n",
      "\n",
      "+  Computed class weights (for training):\n",
      "  [0] Normal                    weight: 0.467\n",
      "  [1] Anxiety                   weight: 1.991\n",
      "  [2] Depression                weight: 0.479\n",
      "  [3] Stress                    weight: 3.126\n",
      "  [4] Suicidal                  weight: 0.677\n",
      "  [5] Bipolar                   weight: 2.871\n",
      "  [6] Personality disorder      weight: 8.048\n",
      "\n",
      "+ Saved: models/mental_health_roberta/class_weights.json\n"
     ]
    }
   ],
   "source": [
    "# ============= CLASS BALANCING ANALYSIS =============\n",
    "print(\"\\n[6/8] Analyzing class balance...\")\n",
    "\n",
    "label_counts = df['label'].value_counts().sort_index()\n",
    "max_count = label_counts.max()\n",
    "min_count = label_counts.min()\n",
    "imbalance_ratio = max_count / min_count\n",
    "\n",
    "print(f\"\\n+ Class Balance Analysis:\")\n",
    "print(f\"Largest class:  {label_counts.idxmax()} with {max_count} samples\")\n",
    "print(f\"Smallest class: {label_counts.idxmin()} with {min_count} samples\")\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "# Calculate class weights for training\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(df['label']),\n",
    "    y=df['label']\n",
    ")\n",
    "\n",
    "print(f\"\\n+  Computed class weights (for training):\")\n",
    "for idx, weight in enumerate(class_weights):\n",
    "    class_name = [k for k, v in CLASS_MAPPING.items() if v == idx][0]\n",
    "    print(f\"  [{idx}] {class_name:<25} weight: {weight:.3f}\")\n",
    "\n",
    "# Save class weights\n",
    "class_weights_dict = {int(idx): float(weight) for idx, weight in enumerate(class_weights)}\n",
    "with open('models/mental_health_roberta/class_weights.json', 'w') as f:\n",
    "    json.dump(class_weights_dict, f, indent=2)\n",
    "print(\"\\n+ Saved: models/mental_health_roberta/class_weights.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7c86610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7/8] Creating stratified train/val/test splits...\n",
      "\n",
      "+ Split complete:\n",
      "Train:        35058 samples ( 70.0%)\n",
      "Validation:    7512 samples ( 15.0%)\n",
      "Test:          7513 samples ( 15.0%)\n",
      "\n",
      "+ Class distribution across splits:\n",
      "\n",
      "Class                        Train      Val     Test\n",
      "-------------------------------------------------------\n",
      "Normal                       10716     2296     2296\n",
      "Anxiety                       2515      539      539\n",
      "Depression                   10462     2241     2242\n",
      "Stress                        1602      343      344\n",
      "Suicidal                      7397     1585     1585\n",
      "Bipolar                       1744      374      374\n",
      "Personality disorder           622      134      133\n"
     ]
    }
   ],
   "source": [
    "# ============= STRATIFIED SPLIT =============\n",
    "print(\"\\n[7/8] Creating stratified train/val/test splits...\")\n",
    "\n",
    "# 70% train, 15% val, 15% test\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.3, \n",
    "    stratify=df['label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, \n",
    "    test_size=0.5, \n",
    "    stratify=temp_df['label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n+ Split complete:\")\n",
    "print(f\"{'Train:':<12} {len(train_df):>6} samples ({len(train_df)/len(df)*100:>5.1f}%)\")\n",
    "print(f\"{'Validation:':<12} {len(val_df):>6} samples ({len(val_df)/len(df)*100:>5.1f}%)\")\n",
    "print(f\"{'Test:':<12} {len(test_df):>6} samples ({len(test_df)/len(df)*100:>5.1f}%)\")\n",
    "\n",
    "# Verify stratification\n",
    "print(\"\\n+ Class distribution across splits:\")\n",
    "print(f\"\\n{'Class':<25} {'Train':>8} {'Val':>8} {'Test':>8}\")\n",
    "print(\"-\" * 55)\n",
    "for class_name, class_idx in sorted(CLASS_MAPPING.items(), key=lambda x: x[1]):\n",
    "    train_count = (train_df['label'] == class_idx).sum()\n",
    "    val_count = (val_df['label'] == class_idx).sum()\n",
    "    test_count = (test_df['label'] == class_idx).sum()\n",
    "    print(f\"{class_name:<25} {train_count:>8} {val_count:>8} {test_count:>8}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaecb957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[8/8] Saving processed data...\n",
      "+ Saved:\n",
      "   - data/train.csv\n",
      "   - data/val.csv\n",
      "   - data/test.csv\n"
     ]
    }
   ],
   "source": [
    "# ============= SAVE DATA =============\n",
    "print(\"\\n[8/8] Saving processed data...\")\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Save only text and label columns\n",
    "train_df[['statement', 'label']].rename(columns={'statement': 'text'}).to_csv('data/train.csv', index=False)\n",
    "val_df[['statement', 'label']].rename(columns={'statement': 'text'}).to_csv('data/val.csv', index=False)\n",
    "test_df[['statement', 'label']].rename(columns={'statement': 'text'}).to_csv('data/test.csv', index=False)\n",
    "\n",
    "print(\"+ Saved:\")\n",
    "print(\"   - data/train.csv\")\n",
    "print(\"   - data/val.csv\")\n",
    "print(\"   - data/test.csv\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
